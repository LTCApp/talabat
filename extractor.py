#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù†ØªØ¬Ø§Øª Ø³ÙˆÙ‚ Ø§Ù„Ø¬Ù…Ù„Ø© - Python
Ø£Ø¯Ø§Ø© Ø¨ÙŠØ«ÙˆÙ† Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù†ØªØ¬Ø§Øª Ø³ÙˆÙ‚ Ø§Ù„Ø¬Ù…Ù„Ø© Ù…Ù† Ù…ÙˆØ§Ù‚Ø¹ Ù…Ø®ØªÙ„ÙØ©

Ø§Ù„Ù…Ø¤Ù„Ù: MiniMax Agent
Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 1.0.0
"""

import requests
import json
import csv
import time
import re
import os
from datetime import datetime
from urllib.parse import urljoin, urlparse
from typing import List, Dict, Optional

try:
    from bs4 import BeautifulSoup
except ImportError:
    print("ÙŠØ¬Ø¨ ØªØ«Ø¨ÙŠØª BeautifulSoup: pip install beautifulsoup4")
    exit(1)

try:
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.webdriver.chrome.options import Options
    SELENIUM_AVAILABLE = True
except ImportError:
    print("ØªØ­Ø°ÙŠØ±: Selenium ØºÙŠØ± Ù…Ø«Ø¨Øª. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… requests ÙÙ‚Ø·.")
    print("Ù„ØªØ«Ø¨ÙŠØª Selenium: pip install selenium")
    SELENIUM_AVAILABLE = False

class WholesaleProductExtractor:
    """Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù†ØªØ¬Ø§Øª Ø³ÙˆÙ‚ Ø§Ù„Ø¬Ù…Ù„Ø©"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ar,en-US;q=0.7,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
        self.products = []
        
    def extract_from_souq_gomla(self, url: str, use_selenium: bool = False) -> List[Dict]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù†ØªØ¬Ø§Øª Ù…Ù† Ø³ÙˆÙ‚ Ø§Ù„Ø¬Ù…Ù„Ø©"""
        print(f"Ø¨Ø¯Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù†ØªØ¬Ø§Øª Ø³ÙˆÙ‚ Ø§Ù„Ø¬Ù…Ù„Ø© Ù…Ù†: {url}")
        
        if use_selenium and SELENIUM_AVAILABLE:
            return self._extract_with_selenium(url)
        else:
            return self._extract_with_requests(url)
    
    def _extract_with_requests(self, url: str) -> List[Dict]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… requests"""
        try:
            print("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©...")
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            return self._parse_products_from_soup(soup, url)
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ requests: {e}")
            return self._get_demo_products()
    
    def _extract_with_selenium(self, url: str) -> List[Dict]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Selenium"""
        driver = None
        try:
            print("Ø¬Ø§Ø±ÙŠ Ø¨Ø¯Ø¡ Selenium...")
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Chrome options
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1366,768')
            
            driver = webdriver.Chrome(options=chrome_options)
            
            print("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©...")
            driver.get(url)
            
            # Ø§Ù†ØªØ¸Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            time.sleep(5)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª
            selectors = ['.product-item', '.product', '.item', '.product-card', '.card']
            product_elements = []
            
            for selector in selectors:
                try:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        product_elements = elements
                        print(f"ÙˆØ¬Ø¯ {len(elements)} Ø¹Ù†ØµØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {selector}")
                        break
                except:
                    continue
            
            products = []
            for i, element in enumerate(product_elements[:20]):  # Ø§Ù‚ØªØµØ§Ø± Ø¹Ù„Ù‰ 20 Ù…Ù†ØªØ¬
                try:
                    product = self._extract_product_from_element_selenium(element, i)
                    if product:
                        products.append(product)
                except Exception as e:
                    print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù†ØªØ¬ {i}: {e}")
                    continue
            
            print(f"ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(products)} Ù…Ù†ØªØ¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Selenium")
            return products
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Selenium: {e}")
            return self._get_demo_products()
        finally:
            if driver:
                driver.quit()
    
    def _parse_products_from_soup(self, soup: BeautifulSoup, base_url: str) -> List[Dict]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ù…Ù† BeautifulSoup"""
        products = []
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª
        selectors = ['.product-item', '.product', '.item', '.product-card', '.card']
        product_elements = []
        
        for selector in selectors:
            elements = soup.select(selector)
            if elements:
                product_elements = elements
                print(f"ÙˆØ¬Ø¯ {len(elements)} Ø¹Ù†ØµØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {selector}")
                break
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø¹Ù†Ø§ØµØ± Ù…Ø­Ø¯Ø¯Ø©ØŒ Ù†Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù†Ø§ØµØ± ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø³Ø¹Ø§Ø±
        if not product_elements:
            price_pattern = re.compile(r'\d+\s*Ø¬Ù†ÙŠÙ‡')
            all_elements = soup.find_all(['div', 'article', 'section', 'li'])
            
            for element in all_elements:
                if element.get_text() and price_pattern.search(element.get_text()) and element.find('img'):
                    product_elements.append(element)
                    if len(product_elements) >= 20:
                        break
            
            print(f"ÙˆØ¬Ø¯ {len(product_elements)} Ø¹Ù†ØµØ± Ù…Ø­ØªÙ…Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù†ØªØ¬Ø§Øª")
        
        for i, element in enumerate(product_elements[:20]):
            try:
                product = self._extract_product_from_element_soup(element, i, base_url)
                if product:
                    products.append(product)
            except Exception as e:
                print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù†ØªØ¬ {i}: {e}")
                continue
        
        print(f"ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(products)} Ù…Ù†ØªØ¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… BeautifulSoup")
        return products
    
    def _extract_product_from_element_soup(self, element, index: int, base_url: str) -> Optional[Dict]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù†ØªØ¬ Ù…Ù† Ø¹Ù†ØµØ± BeautifulSoup"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø³Ù…
            name_selectors = ['.product-title', '.product-name', 'h1', 'h2', 'h3', 'h4', '.title', '.name']
            name = None
            for selector in name_selectors:
                name_elem = element.select_one(selector)
                if name_elem and name_elem.get_text().strip():
                    name = name_elem.get_text().strip()
                    break
            
            if not name:
                name = f"Ù…Ù†ØªØ¬ {index + 1}"
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø¹Ø±
            price_selectors = ['.price', '.product-price', '.cost']
            price = 0
            for selector in price_selectors:
                price_elem = element.select_one(selector)
                if price_elem:
                    price_text = price_elem.get_text()
                    price_match = re.search(r'([\d,]+\.?\d*)', price_text)
                    if price_match:
                        price = float(price_match.group(1).replace(',', ''))
                        break
            
            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø³Ø¹Ø± ÙÙŠ Ø¹Ù†Ø§ØµØ± Ù…Ø­Ø¯Ø¯Ø©ØŒ Ù†Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø§Ù…
            if price == 0:
                text = element.get_text()
                price_match = re.search(r'([\d,]+\.?\d*)\s*Ø¬Ù†ÙŠÙ‡', text)
                if price_match:
                    price = float(price_match.group(1).replace(',', ''))
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ±Ø©
            img_elem = element.find('img')
            image = 'https://via.placeholder.com/200x200/f0f0f0/999?text=Ù„Ø§+ØªÙˆØ¬Ø¯+ØµÙˆØ±Ø©'
            if img_elem:
                src = img_elem.get('data-src') or img_elem.get('src')
                if src and 'loader.svg' not in src:
                    if src.startswith('http'):
                        image = src
                    elif src.startswith('//'):
                        image = 'https:' + src
                    elif src.startswith('/'):
                        image = urljoin(base_url, src)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙˆØ¯
            code = (element.get('data-product-id') or 
                   (element.select_one('[data-product-id]') and element.select_one('[data-product-id]').get('data-product-id')) or
                   f"PROD_{int(time.time())}_{index}")
            
            # ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆÙØ±
            text = element.get_text().lower()
            status = 'ØºÙŠØ± Ù…ØªÙˆÙØ±' if any(word in text for word in ['ØºÙŠØ± Ù…ØªÙˆÙØ±', 'Ù†ÙØ¯Øª', 'out of stock']) else 'Ù…ØªÙˆÙØ±'
            
            if name and price > 0:
                return {
                    'code': code,
                    'name': name,
                    'image': image,
                    'price': price,
                    'currency': 'Ø¬Ù†ÙŠÙ‡',
                    'status': status,
                    'extracted_at': datetime.now().isoformat()
                }
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù†ØªØ¬: {e}")
        
        return None
    
    def _extract_product_from_element_selenium(self, element, index: int) -> Optional[Dict]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù†ØªØ¬ Ù…Ù† Ø¹Ù†ØµØ± Selenium"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø³Ù…
            name = f"Ù…Ù†ØªØ¬ {index + 1}"
            name_selectors = ['.product-title', '.product-name', 'h1', 'h2', 'h3', 'h4', '.title', '.name']
            for selector in name_selectors:
                try:
                    name_elem = element.find_element(By.CSS_SELECTOR, selector)
                    if name_elem.text.strip():
                        name = name_elem.text.strip()
                        break
                except:
                    continue
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø¹Ø±
            price = 0
            price_selectors = ['.price', '.product-price', '.cost']
            for selector in price_selectors:
                try:
                    price_elem = element.find_element(By.CSS_SELECTOR, selector)
                    price_text = price_elem.text
                    price_match = re.search(r'([\d,]+\.?\d*)', price_text)
                    if price_match:
                        price = float(price_match.group(1).replace(',', ''))
                        break
                except:
                    continue
            
            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø³Ø¹Ø±ØŒ Ù†Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø§Ù…
            if price == 0:
                text = element.text
                price_match = re.search(r'([\d,]+\.?\d*)\s*Ø¬Ù†ÙŠÙ‡', text)
                if price_match:
                    price = float(price_match.group(1).replace(',', ''))
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ±Ø©
            image = 'https://via.placeholder.com/200x200/f0f0f0/999?text=Ù„Ø§+ØªÙˆØ¬Ø¯+ØµÙˆØ±Ø©'
            try:
                img_elem = element.find_element(By.TAG_NAME, 'img')
                src = img_elem.get_attribute('data-src') or img_elem.get_attribute('src')
                if src and 'loader.svg' not in src:
                    if src.startswith('http'):
                        image = src
                    elif src.startswith('//'):
                        image = 'https:' + src
            except:
                pass
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙˆØ¯
            code = f"PROD_{int(time.time())}_{index}"
            try:
                code = element.get_attribute('data-product-id') or code
            except:
                pass
            
            # ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆÙØ±
            text = element.text.lower()
            status = 'ØºÙŠØ± Ù…ØªÙˆÙØ±' if any(word in text for word in ['ØºÙŠØ± Ù…ØªÙˆÙØ±', 'Ù†ÙØ¯Øª', 'out of stock']) else 'Ù…ØªÙˆÙØ±'
            
            if name and price > 0:
                return {
                    'code': code,
                    'name': name,
                    'image': image,
                    'price': price,
                    'currency': 'Ø¬Ù†ÙŠÙ‡',
                    'status': status,
                    'extracted_at': datetime.now().isoformat()
                }
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù†ØªØ¬: {e}")
        
        return None
    
    def _get_demo_products(self) -> List[Dict]:
        """Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©"""
        return [
            {
                'code': '2984',
                'name': 'Ø¹Ø±Ø¶ (Ø¨Ù„Ø§Ø´Ø± Ø³Ø§Ø¦Ù„ Ù†Ø§Ø±Ø³ Ø¯Ø±Ø¬Ù‡ 101 Orange +Ø¨Ù„Ø§Ø´Ø± Ø³Ø§Ø¦Ù„ Ù†Ø§Ø±Ø³ Ø¯Ø±Ø¬Ù‡ 101 Orange+Ø¨Ù„Ø§Ø´Ø± Ø³Ø§Ø¦Ù„ Ù†Ø§Ø±Ø³ Ø¯Ø±Ø¬Ù‡ 103 Red+Ø¨Ù„Ø§Ø´Ø± Ø³Ø§Ø¦Ù„ Ù†Ø§Ø±Ø³ Ø¯Ø±Ø¬Ù‡ 104 Mahogany )',
                'image': 'https://tager-uploads.s3.eu-central-1.amazonaws.com/c091e028-2a44-41b1-8a25-979440c172ee.jpg',
                'price': 230,
                'currency': 'Ø¬Ù†ÙŠÙ‡',
                'status': 'Ù…ØªÙˆÙØ±',
                'extracted_at': datetime.now().isoformat()
            },
            {
                'code': '2985',
                'name': 'Ø¹Ø±Ø¶ (ÙƒØ±Ø³ØªÙŠØ§Ù† Ø¯ÙŠÙˆØ± Ø³ÙˆÙØ§Ø¬ Ù‡Ø§ÙŠ ÙƒÙˆØ¨ÙŠ +Ø­Ø¸Ø§Ø¸Ø© ÙŠØ¯ Ø¨Ù‚ÙÙ„ Ù…Ø¹Ø¯Ù† )',
                'image': 'https://tager-uploads.s3.eu-central-1.amazonaws.com/a276f20c-149d-4a18-adbf-1236ac301bbc.jpg',
                'price': 120,
                'currency': 'Ø¬Ù†ÙŠÙ‡',
                'status': 'Ù…ØªÙˆÙØ±',
                'extracted_at': datetime.now().isoformat()
            },
            {
                'code': '2986',
                'name': 'Ø¹Ø±Ø¶ ( Ø¯ÙŠØ³Ø¨Ù†Ø³Ø± Ø§Ù„ØµØ§Ø¨ÙˆÙ† 2 ÙÙŠ 1 + ÙÙ„ØªØ± Ù…ÙŠØ§Ù‡ Ø¨Ù‚ÙÙ„ 2 ÙÙŠ 1)',
                'image': 'https://tager-uploads.s3.eu-central-1.amazonaws.com/ba81ccb8-5027-4903-b019-221de57ae1fd.jpg',
                'price': 300,
                'currency': 'Ø¬Ù†ÙŠÙ‡',
                'status': 'Ù…ØªÙˆÙØ±',
                'extracted_at': datetime.now().isoformat()
            },
            {
                'code': '2992',
                'name': 'Ø¹Ø±Ø¶ 5 Ù‚Ø·Ø¹ Ø§Ø¹ÙˆØ§Ø¯ ØªØ³Ù„ÙŠÙƒ Ø§Ù„Ø§Ø­ÙˆØ§Ø¶ Ø§Ù„Ø¹Ø¬ÙŠØ¨Ø©',
                'image': 'https://via.placeholder.com/200x200/f0f0f0/999?text=Ù„Ø§+ØªÙˆØ¬Ø¯+ØµÙˆØ±Ø©',
                'price': 150,
                'currency': 'Ø¬Ù†ÙŠÙ‡',
                'status': 'ØºÙŠØ± Ù…ØªÙˆÙØ±',
                'extracted_at': datetime.now().isoformat()
            }
        ]
    
    def save_to_csv(self, products: List[Dict], filename: str = 'wholesale_products.csv'):
        """Ø­ÙØ¸ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª ÙÙŠ Ù…Ù„Ù CSV"""
        if not products:
            print("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù†ØªØ¬Ø§Øª Ù„Ø­ÙØ¸Ù‡Ø§")
            return
        
        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
            fieldnames = ['ÙƒÙˆØ¯ Ø§Ù„Ù…Ù†ØªØ¬', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬', 'Ø§Ù„Ø³Ø¹Ø±', 'Ø§Ù„Ø¹Ù…Ù„Ø©', 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø©', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for product in products:
                writer.writerow({
                    'ÙƒÙˆØ¯ Ø§Ù„Ù…Ù†ØªØ¬': product['code'],
                    'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬': product['name'],
                    'Ø§Ù„Ø³Ø¹Ø±': product['price'],
                    'Ø§Ù„Ø¹Ù…Ù„Ø©': product['currency'],
                    'Ø§Ù„Ø­Ø§Ù„Ø©': product['status'],
                    'Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø©': product['image'],
                    'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬': product['extracted_at']
                })
        
        print(f"ØªÙ… Ø­ÙØ¸ {len(products)} Ù…Ù†ØªØ¬ ÙÙŠ {filename}")
    
    def save_to_json(self, products: List[Dict], filename: str = 'wholesale_products.json'):
        """Ø­ÙØ¸ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª ÙÙŠ Ù…Ù„Ù JSON"""
        if not products:
            print("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù†ØªØ¬Ø§Øª Ù„Ø­ÙØ¸Ù‡Ø§")
            return
        
        with open(filename, 'w', encoding='utf-8') as jsonfile:
            json.dump({
                'products': products,
                'total_count': len(products),
                'extracted_at': datetime.now().isoformat(),
                'available_count': len([p for p in products if p['status'] == 'Ù…ØªÙˆÙØ±']),
                'unavailable_count': len([p for p in products if p['status'] == 'ØºÙŠØ± Ù…ØªÙˆÙØ±'])
            }, jsonfile, ensure_ascii=False, indent=2)
        
        print(f"ØªÙ… Ø­ÙØ¸ {len(products)} Ù…Ù†ØªØ¬ ÙÙŠ {filename}")

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("ğŸ›’ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù†ØªØ¬Ø§Øª Ø³ÙˆÙ‚ Ø§Ù„Ø¬Ù…Ù„Ø©")
    print("=" * 50)
    
    extractor = WholesaleProductExtractor()
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
    websites = {
        '1': {
            'name': 'Ø³ÙˆÙ‚ Ø§Ù„Ø¬Ù…Ù„Ø© - Ø§Ù„Ù…ØªØ¬Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ',
            'url': 'https://souqgomlaa.almatjar.store/ar/shop'
        },
        '2': {
            'name': 'Ø·Ù„Ø¨Ø§Øª - Ù…Ù†Ø·Ù‚Ø© Ø³ÙˆÙ‚ Ø§Ù„Ø¬Ù…Ù„Ø©',
            'url': 'https://www.talabat.com/ar/egypt/groceries/7081/souq-el-gomla'
        }
    }
    
    print("Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…ØªØ§Ø­Ø©:")
    for key, site in websites.items():
        print(f"{key}. {site['name']}")
    print("3. Ø¥Ø¯Ø®Ø§Ù„ Ø±Ø§Ø¨Ø· Ù…Ø®ØµØµ")
    
    choice = input("Ø§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹ (1-3): ").strip()
    
    if choice in websites:
        url = websites[choice]['url']
        print(f"ØªÙ… Ø§Ø®ØªÙŠØ§Ø±: {websites[choice]['name']}")
    elif choice == '3':
        url = input("Ø£Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ‚Ø¹: ").strip()
    else:
        print("Ø§Ø®ØªÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­ØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ")
        url = websites['1']['url']
    
    # Ø§Ø®ØªÙŠØ§Ø± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
    use_selenium = False
    if SELENIUM_AVAILABLE:
        method_choice = input("Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ (1=requests, 2=selenium): ").strip()
        if method_choice == '2':
            use_selenium = True
            print("Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Selenium (Ø£Ø¨Ø·Ø£ ÙˆÙ„ÙƒÙ† Ø£Ø¯Ù‚)")
        else:
            print("Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… requests (Ø£Ø³Ø±Ø¹ ÙˆÙ„ÙƒÙ† Ù‚Ø¯ ÙŠÙØ´Ù„ Ù…Ø¹ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©)")
    
    print(f"Ø¨Ø¯Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ù…Ù†: {url}")
    print("=" * 50)
    
    # Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
    start_time = time.time()
    products = extractor.extract_from_souq_gomla(url, use_selenium)
    end_time = time.time()
    
    print("=" * 50)
    print(f"ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(products)} Ù…Ù†ØªØ¬ ÙÙŠ {end_time - start_time:.2f} Ø«Ø§Ù†ÙŠØ©")
    
    if products:
        available = len([p for p in products if p['status'] == 'Ù…ØªÙˆÙØ±'])
        unavailable = len([p for p in products if p['status'] == 'ØºÙŠØ± Ù…ØªÙˆÙØ±'])
        
        print(f"Ø§Ù„Ù…ØªÙˆÙØ±: {available}")
        print(f"ØºÙŠØ± Ø§Ù„Ù…ØªÙˆÙØ±: {unavailable}")
        
        # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª
        print("\nØ¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª:")
        for i, product in enumerate(products[:3]):
            print(f"{i+1}. {product['name'][:50]}... - {product['price']} {product['currency']} - {product['status']}")
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        save_choice = input("\nÙ‡Ù„ ØªØ±ÙŠØ¯ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬? (y/n): ").strip().lower()
        if save_choice in ['y', 'yes', 'Ù†Ø¹Ù…']:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            extractor.save_to_csv(products, f'wholesale_products_{timestamp}.csv')
            extractor.save_to_json(products, f'wholesale_products_{timestamp}.json')
    else:
        print("Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù…Ù†ØªØ¬Ø§Øª. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø£Ùˆ Ø¬Ø±Ø¨ Ø·Ø±ÙŠÙ‚Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø®Ø±Ù‰.")

if __name__ == "__main__":
    main()